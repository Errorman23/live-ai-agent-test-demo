APP_ENV=dev
API_PREFIX=/api/v1
# Langfuse Docker/compose credentials and bootstrap identity are configured in:
# infra/langfuse/infra.env (copy from infra/langfuse/infra.env.example)
TOGETHER_API_KEY=your_together_api_key
TOGETHER_BASE_URL=https://api.together.xyz/v1
TOGETHER_MODEL=openai/gpt-oss-20b
AGENT_REASONING_EFFORT=low
APP_HOST=127.0.0.1
APP_PORT=8000
CHAINLIT_HOST=127.0.0.1
CHAINLIT_PORT=8501
CHAINLIT_RUN_TIMEOUT_SECONDS=300
CHAINLIT_RUN_POLL_INTERVAL_SECONDS=1.0
TESTING_UI_HOST=127.0.0.1
TESTING_UI_PORT=8502

LLM_TIMEOUT_SECONDS=30
LLM_MAX_RETRIES=2
LLM_SAFETY_MARGIN_TOKENS=512
PLANNER_MAX_TOKENS=1200
COMPOSER_MAX_TOKENS=2000
JUDGE_MAX_TOKENS=900
LLM_JUDGE_ENABLED=true
LLM_JUDGE_MODEL=Qwen/Qwen3-235B-A22B-Instruct-2507-tput
LLM_JUDGE_REASONING_EFFORT=medium
EVAL_REPEAT_COUNT=5
EVAL_DEFAULT_PARALLELISM=1

REQUIRE_POSTGRES_CHECKPOINTER=true
LANGGRAPH_POSTGRES_URI=postgresql://postgres:postgres@localhost:5432/langgraph

LANGFUSE_ENABLED=false
LANGFUSE_HOST=http://localhost:3000
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_PROJECT_ID=
LANGFUSE_POSTGRES_URI=postgresql://postgres:postgres@127.0.0.1:5432/postgres
LANGFUSE_EVAL_DATASET_NAME=agent-safety-evals
LANGFUSE_EVAL_DELAY_SECONDS=10
LANGFUSE_NATIVE_EVALUATOR_BOOTSTRAP_ENABLED=false

INTERNAL_DB_PATH=backend/data/internal_company.db
ARTIFACTS_DIR=backend/data/artifacts
TEMPLATES_DIR=backend/app/templates
INTERNAL_PDF_DOC_TYPE_DEFAULT=proposal
TAVILY_API_KEY=
TAVILY_SEARCH_URL=https://api.tavily.com/search
TAVILY_SEARCH_DEPTH=advanced
TAVILY_TOPIC=general
TAVILY_MAX_RESULTS=6
SILICONFLOW_API_KEY=
SILICONFLOW_BASE_URL=https://api.siliconflow.com/v1
SILICONFLOW_MT_MODEL=tencent/Hunyuan-MT-7B
SILICONFLOW_TIMEOUT_SECONDS=45

PROMPTFOO_ENABLED=true
# Requires Node.js 20+ in the shell that starts backend.
# start_demo.sh will auto-resolve this to an absolute npx path when possible.
PROMPTFOO_COMMAND='npx -y promptfoo@0.120.25'
PROMPTFOO_PORT=15500
PROMPTFOO_OUTPUT_DIR=backend/data/artifacts/promptfoo
PROMPTFOO_LOG_PATH=.run/promptfoo_view.log
